{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Driver [C:\\Users\\rod\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## NASA Mars News Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get title and news article\n",
    "news_title = soup.find('div',class_=\"content_title\")\n",
    "news_p = soup.find('div',class_='article_teaser_body')                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celebrate Mars Reconnaissance Orbiter's Views From Above\n",
      "Marking its 15th anniversary since launch, one of the oldest spacecraft at the Red Planet has provided glimpses of dust devils, avalanches, and more.\n"
     ]
    }
   ],
   "source": [
    "# print latest news title and paragraph text\n",
    "print(news_title.text)\n",
    "print(news_p.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "image_url = 'https://spaceimages-mars.com/' \n",
    "browser.visit(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with'html.parser'\n",
    "html1 = browser.html\n",
    "soup1 = BeautifulSoup(html1, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"floating_text_area\">\n",
      "<h2 class=\"brand_title\">FEATURED IMAGE</h2>\n",
      "<h1 class=\"media_feature_title\">Dusty Space Cloud</h1>\n",
      "<br/>\n",
      "<a class=\"showimg fancybox-thumbs\" href=\"image/featured/mars2.jpg\" target=\"_blank\"> <button class=\"btn btn-outline-light\"> FULL IMAGE</button></a>\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    "# retrieve image url for the featured image\n",
    "images = soup1.find_all('div', class_='floating_text_area')\n",
    "print(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "https://spaceimages-mars.com/image/featured/mars2.jpg\n"
     ]
    }
   ],
   "source": [
    "# iterate through each\n",
    "for image in images:\n",
    "    link = image.find('a')\n",
    "    href = link['href']\n",
    "    print('===============')\n",
    "    print('https://spaceimages-mars.com/' + href)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url to scrape\n",
    "url ='https://galaxyfacts-mars.com/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                         0                1                2\n",
       " 0  Mars - Earth Comparison             Mars            Earth\n",
       " 1                Diameter:         6,779 km        12,742 km\n",
       " 2                    Mass:  6.39 × 10^23 kg  5.97 × 10^24 kg\n",
       " 3                   Moons:                2                1\n",
       " 4       Distance from Sun:   227,943,824 km   149,598,262 km\n",
       " 5          Length of Year:   687 Earth days      365.24 days\n",
       " 6             Temperature:     -87 to -5 °C      -88 to 58°C,\n",
       "                       0                              1\n",
       " 0  Equatorial Diameter:                       6,792 km\n",
       " 1       Polar Diameter:                       6,752 km\n",
       " 2                 Mass:  6.39 × 10^23 kg (0.11 Earths)\n",
       " 3                Moons:          2 ( Phobos & Deimos )\n",
       " 4       Orbit Distance:       227,943,824 km (1.38 AU)\n",
       " 5         Orbit Period:           687 days (1.9 years)\n",
       " 6  Surface Temperature:                   -87 to -5 °C\n",
       " 7         First Record:              2nd millennium BC\n",
       " 8          Recorded By:           Egyptian astronomers]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read_html to scrape tabular data\n",
    "tables = pd.read_html(url)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "image_url = 'https://marshemispheres.com/' \n",
    "browser.visit(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all pages\n",
    "\n",
    "# HTML object\n",
    "html2 = browser.html\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html2, 'html.parser')\n",
    "# Retrieve all elements that contain image link information\n",
    "hemispheres = soup.find_all('div', class_='description')\n",
    "# list of links for hemisphere pages\n",
    "hemispheres_list=[]  \n",
    "\n",
    "\n",
    "# Iterate through each book\n",
    "for hemisphere in hemispheres:\n",
    "    \n",
    "    # Use Beautiful Soup's find() method to navigate and retrieve attributes\n",
    "    link = hemisphere.find('a')\n",
    "    href = link['href']\n",
    "    hemispheres_list.append('https://marshemispheres.com/' + href)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dictioinaries of hemisphere image urls \n",
    "hemisphere_image_urls=[]\n",
    "\n",
    "# get image url and titles\n",
    "for hemisphere in hemispheres_list:\n",
    "    # URL of page to be scraped\n",
    "    browser.visit(hemisphere)\n",
    "    \n",
    "    #HTML object\n",
    "    html3 = browser.html\n",
    "    \n",
    "    #Parse HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html3, 'html.parser')\n",
    "    \n",
    "    # Retrieve all elements that contain image link information\n",
    "    results = soup.find_all('div', class_='cover')\n",
    "    \n",
    "    for result in results:\n",
    "        title = result.find('h2',class_='title').text\n",
    "    \n",
    "    # get the image url and title\n",
    "    images = soup.find_all('div', class_ ='downloads')\n",
    "    \n",
    "    for image in images:\n",
    "        ul = image.find('ul')\n",
    "        li = ul.find('li')\n",
    "        link = li.find('a')\n",
    "        href1 = link['href']\n",
    "        img_url = 'https://marshemispheres.com/' + href1        \n",
    "        post = {\n",
    "            'title': title,\n",
    "            'img_url': img_url,\n",
    "            }\n",
    "        hemisphere_image_urls.append(post)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/full.jpg'}, {'title': 'Schiaparelli Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/schiaparelli_enhanced-full.jpg'}, {'title': 'Syrtis Major Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/syrtis_major_enhanced-full.jpg'}, {'title': 'Valles Marineris Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/valles_marineris_enhanced-full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "print(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
